{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7010b4ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7010b4ff",
        "outputId": "ca22b9af-9a6b-4215-f1a3-dffe3b21af5f"
      },
      "outputs": [],
      "source": [
        "# loading dependencies\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import tqdm\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4fe0e48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4fe0e48",
        "outputId": "19e6a43d-5772-46dd-d7d4-ed3a18972c73"
      },
      "outputs": [],
      "source": [
        "# load resnet50 with IMAGENET weights\n",
        "\n",
        "model = models.resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2b00bf1",
      "metadata": {
        "id": "d2b00bf1"
      },
      "outputs": [],
      "source": [
        "# customize classification head\n",
        "\n",
        "old_classes = model.fc.in_features\n",
        "new_classes = 45\n",
        "\n",
        "model.fc = nn.Linear(old_classes, new_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "831eb787",
      "metadata": {
        "id": "831eb787"
      },
      "outputs": [],
      "source": [
        "# freeze all layers except layer 4  and FCL and moving to GPU\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if 'layer4' not in name and 'fc' not in name:\n",
        "        param.requires_grad = False # frozen\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a480c93",
      "metadata": {
        "id": "4a480c93"
      },
      "outputs": [],
      "source": [
        "# set up optimizers and a LR scheduler\n",
        "\n",
        "fc_params = list(model.fc.parameters())\n",
        "layer4_params = list(model.layer4.parameters())\n",
        "\n",
        "# optimizer with different LRs for FC & Layer4\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': fc_params, 'lr': 1e-4}, # bigger steps for faster convergence\n",
        "    {'params': layer4_params, 'lr': 1e-5} # slower steps for rich feature representations\n",
        "], weight_decay = 1e-4 # Regularization technique - keeps weights small and increases val. acc. on small datasets by reducing risk of overfitting.\n",
        ")\n",
        "\n",
        "# LR scheduler\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( # for small datasets val. acc. plateaus fast, when that happens we reduce LR\n",
        "    optimizer,\n",
        "    mode = 'min',\n",
        "    patience = 3,\n",
        "    factor = 0.1\n",
        ")\n",
        "\n",
        "# loss function\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2196300e",
      "metadata": {
        "id": "2196300e"
      },
      "outputs": [],
      "source": [
        "# data augmentations and dataloaders\n",
        "\n",
        "img_size = 224\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.RandomVerticalFlip(p = 0.2),\n",
        "    transforms.RandomRotation(degrees = 15),\n",
        "    transforms.RandomResizedCrop(img_size, scale = (0.8, 1.0)),\n",
        "    transforms.ColorJitter(\n",
        "        brightness = 0.2,\n",
        "        contrast = 0.2,\n",
        "        saturation = 0.2,\n",
        "        hue = 0.02\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "# data dirs\n",
        "\n",
        "train_dir = 'data/train/'\n",
        "valid_dir = 'data/val/'\n",
        "\n",
        "train_ds = datasets.ImageFolder(train_dir, transform = train_transforms)\n",
        "val_ds = datasets.ImageFolder(valid_dir, transform = valid_transforms)\n",
        "\n",
        "# dataloaders\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        "    num_workers = 4,\n",
        "    pin_memory = True\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size = 32,\n",
        "    shuffle = False,\n",
        "    num_workers = 4,\n",
        "    pin_memory = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b6392ba8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6392ba8",
        "outputId": "128f0aaa-e0ad-408f-adcc-186a6333decd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Karthick Srinivas S\\AppData\\Local\\Temp\\ipykernel_1228\\382614304.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "Train Epoch 1/10:   0%|          | 0/344 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Karthick Srinivas S\\AppData\\Local\\Temp\\ipykernel_1228\\382614304.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Train Epoch 1/10: 100%|██████████| 344/344 [02:28<00:00,  2.32it/s]\n",
            "Valid:   0%|          | 0/87 [00:00<?, ?it/s]C:\\Users\\Karthick Srinivas S\\AppData\\Local\\Temp\\ipykernel_1228\\382614304.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 2.0768 | Train Acc: 0.6229\n",
            "Val   Loss: 0.6054 | Val   Acc: 0.8962\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2/10: 100%|██████████| 344/344 [02:27<00:00,  2.33it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.7508 | Train Acc: 0.8449\n",
            "Val   Loss: 0.3032 | Val   Acc: 0.9306\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3/10: 100%|██████████| 344/344 [02:28<00:00,  2.32it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.4990 | Train Acc: 0.8767\n",
            "Val   Loss: 0.2371 | Val   Acc: 0.9403\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4/10: 100%|██████████| 344/344 [02:27<00:00,  2.34it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.3966 | Train Acc: 0.8973\n",
            "Val   Loss: 0.2040 | Val   Acc: 0.9439\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5/10: 100%|██████████| 344/344 [02:27<00:00,  2.32it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:44<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.3367 | Train Acc: 0.9084\n",
            "Val   Loss: 0.1879 | Val   Acc: 0.9447\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6/10: 100%|██████████| 344/344 [02:33<00:00,  2.25it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:42<00:00,  2.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.2885 | Train Acc: 0.9222\n",
            "Val   Loss: 0.1673 | Val   Acc: 0.9512\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 7/10: 100%|██████████| 344/344 [02:27<00:00,  2.33it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.2484 | Train Acc: 0.9326\n",
            "Val   Loss: 0.1648 | Val   Acc: 0.9490\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 8/10: 100%|██████████| 344/344 [02:27<00:00,  2.33it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.2223 | Train Acc: 0.9398\n",
            "Val   Loss: 0.1567 | Val   Acc: 0.9497\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 9/10: 100%|██████████| 344/344 [02:27<00:00,  2.33it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.2055 | Train Acc: 0.9439\n",
            "Val   Loss: 0.1540 | Val   Acc: 0.9512\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 10/10: 100%|██████████| 344/344 [02:27<00:00,  2.34it/s]\n",
            "Valid: 100%|██████████| 87/87 [00:37<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.1825 | Train Acc: 0.9502\n",
            "Val   Loss: 0.1407 | Val   Acc: 0.9559\n",
            "Saved best model checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "\n",
        "epochs = 10\n",
        "patience = 5\n",
        "best_val_loss = np.inf\n",
        "no_improve = 0\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    for imgs, labels in tqdm.tqdm(train_loader, desc = f\"Train Epoch {epoch+1}/{epochs}\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none = True)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # step backward with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        preds = outputs.argmax(dim = 1)\n",
        "        train_correct += (preds ==labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # validation\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm.tqdm(valid_loader, desc = 'Valid'):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            preds = outputs.argmax(dim =  1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(valid_loader.dataset)\n",
        "    val_acc = val_correct / len(valid_loader.dataset)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # early stopping check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improve = 0\n",
        "\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"Saved best model checkpoint.\")\n",
        "\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        print(f\"No improvement for {no_improve}/{patience} epochs.\")\n",
        "\n",
        "        if no_improve >= patience:\n",
        "            print(\"\\nEarly stopping triggered.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c96c285b",
      "metadata": {
        "id": "c96c285b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DogVision (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
